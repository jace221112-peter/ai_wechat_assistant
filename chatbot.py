# chatbot.py
import os
import threading
import time
from typing import List, Dict

from dotenv import load_dotenv
from openai import OpenAI

from langchain.docstore.document import Document
from langchain_community.document_loaders import TextLoader, PyPDFLoader, Docx2txtLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma

from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler


# ---------- å…¨å±€é…ç½® ----------
KNOWLEDGE_DIR = "knowledge"
PERSIST_DIR = "chroma_db"
TOP_K = 3                    # æ£€ç´¢è¿”å›æ–‡æ¡£æ•°
MAX_TURNS = 10               # ä¼šè¯è®°å¿†æœ€å¤šä¿ç•™è½®æ¬¡

# ä¼šè¯è®°å¿†ï¼šsession_id -> List[{role, content}]
SESSION_MEMORIES: Dict[str, List[Dict[str, str]]] = {}


def ensure_dirs():
    if not os.path.exists(KNOWLEDGE_DIR):
        os.makedirs(KNOWLEDGE_DIR)
        print(f"ğŸ“ æœªæ‰¾åˆ° {KNOWLEDGE_DIR}ï¼Œå·²è‡ªåŠ¨åˆ›å»ºã€‚")
    if not os.path.exists(PERSIST_DIR):
        os.makedirs(PERSIST_DIR, exist_ok=True)


# ---------- æ–‡æ¡£åŠ è½½ ----------
def load_docs(folder_path=KNOWLEDGE_DIR) -> List[Document]:
    ensure_dirs()
    docs: List[Document] = []
    for name in os.listdir(folder_path):
        path = os.path.join(folder_path, name)
        if not os.path.isfile(path):
            continue
        ext = os.path.splitext(path)[1].lower()
        try:
            if ext == ".txt":
                loader = TextLoader(path, encoding="utf-8")
            elif ext == ".pdf":
                loader = PyPDFLoader(path)
            elif ext == ".docx":
                loader = Docx2txtLoader(path)
            else:
                print(f"âš ï¸ æš‚ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼š{name}ï¼Œå·²è·³è¿‡ã€‚")
                continue
            loaded = loader.load()
            docs.extend(loaded)
        except Exception as e:
            print(f"âŒ åŠ è½½ {name} å¤±è´¥ï¼š{e}")
    print(f"ğŸ“š æ–‡æ¡£åŠ è½½å®Œæˆï¼Œå…± {len(docs)} æ¡ã€‚")
    return docs


def split_docs(docs: List[Document]) -> List[Document]:
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=500, chunk_overlap=100,
        separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼›", "ï¼Œ", " "]
    )
    chunks = splitter.split_documents(docs)
    print(f"ğŸ§© æ–‡æ¡£åˆ‡åˆ†å®Œæˆï¼Œå…± {len(chunks)} ä¸ªç‰‡æ®µã€‚")
    return chunks


# ---------- DeepSeek å®¢æˆ·ç«¯ ----------
def make_deepseek_client() -> OpenAI:
    load_dotenv()
    api_key = os.getenv("DEEPSEEK_API_KEY")
    if not api_key:
        raise RuntimeError("æœªè®¾ç½® DEEPSEEK_API_KEYï¼Œè¯·åœ¨ .env ä¸­é…ç½®ã€‚")
    client = OpenAI(
        api_key=api_key,
        base_url="https://api.deepseek.com/v1"  # å…¼å®¹ OpenAI æ ¼å¼
    )
    return client


# ---------- å‘é‡åº“ ----------
def make_embeddings():
    # ä¸­æ–‡æ£€ç´¢æ›´ç¨³çš„ bge-m3ï¼ˆCPU å¯è¿è¡Œï¼‰
    return HuggingFaceEmbeddings(model_name="BAAI/bge-m3")


def build_or_update_vectorstore(embeddings) -> Chroma:
    docs = load_docs(KNOWLEDGE_DIR)
    if not docs:
        # å³ä½¿æ²¡æœ‰æ–‡æ¡£ï¼Œä¹Ÿåˆå§‹åŒ–ä¸€ä¸ªç©ºçš„å‘é‡åº“ï¼Œé¿å…æŠ¥é”™
        return Chroma(persist_directory=PERSIST_DIR, embedding_function=embeddings)

    chunks = split_docs(docs)
    # è‹¥å·²å­˜åœ¨åˆ™åœ¨å…¶ä¸Šå¢é‡æ›´æ–°ï¼›é¦–æ¬¡åˆ™æ–°å»º
    if os.listdir(PERSIST_DIR):
        vs = Chroma(persist_directory=PERSIST_DIR, embedding_function=embeddings)
        vs.add_documents(chunks)
        vs.persist()
        print("ğŸ” å‘é‡åº“å¢é‡æ›´æ–°å®Œæˆã€‚")
        return vs
    else:
        vs = Chroma.from_documents(chunks, embeddings, persist_directory=PERSIST_DIR)
        vs.persist()
        print("âœ… å‘é‡åº“åˆ›å»ºå®Œæˆã€‚")
        return vs


# ---------- æ–‡ä»¶å¤¹çƒ­åŠ è½½ç›‘æ§ ----------
class _KnowledgeHandler(FileSystemEventHandler):
    def __init__(self, bot_ref):
        super().__init__()
        self.bot_ref = bot_ref
        self._lock = threading.Lock()
        self._last = 0

    def on_any_event(self, event):
        # é˜²æŠ–ï¼š1ç§’å†…çš„è¿ç»­äº‹ä»¶åªè§¦å‘ä¸€æ¬¡
        now = time.time()
        with self._lock:
            if now - self._last < 1.0:
                return
            self._last = now
        print("ğŸ” æ£€æµ‹åˆ°çŸ¥è¯†åº“å˜æ›´ï¼Œæ­£åœ¨é‡å»ºå‘é‡åº“...")
        self.bot_ref.rebuild_vectorstore()


class DeepSeekBot:
    def __init__(self):
        ensure_dirs()
        self.client = make_deepseek_client()
        self.embeddings = make_embeddings()
        self.vectorstore = build_or_update_vectorstore(self.embeddings)
        self.retriever = self.vectorstore.as_retriever(search_kwargs={"k": TOP_K})
        # äººè®¾ï¼ˆç³»ç»Ÿæç¤ºï¼‰
        self.role = os.getenv(
            "ASSISTANT_ROLE",
            "ä½ æ˜¯ä¸€åèµ„æ·±å”®åå®¢æœï¼Œè¯­æ°”äº²åˆ‡ã€ç¤¼è²Œã€ç®€æ´ï¼Œä¼˜å…ˆä¾æ®å…¬å¸æä¾›çš„çŸ¥è¯†åº“å›ç­”ã€‚"
        )

        # å¯åŠ¨æ–‡ä»¶ç›‘æ§
        self._observer = Observer()
        handler = _KnowledgeHandler(self)
        self._observer.schedule(handler, KNOWLEDGE_DIR, recursive=True)
        self._observer.daemon = True
        self._observer.start()
        print("ğŸ‘€ å·²å¼€å¯çŸ¥è¯†åº“çƒ­åŠ è½½ç›‘æ§ã€‚")

    def rebuild_vectorstore(self):
        self.vectorstore = build_or_update_vectorstore(self.embeddings)
        self.retriever = self.vectorstore.as_retriever(search_kwargs={"k": TOP_K})
        print("ğŸ“¦ å‘é‡åº“å·²é‡å»ºã€‚")

    def _get_memory(self, session_id: str) -> List[Dict[str, str]]:
        mem = SESSION_MEMORIES.setdefault(session_id, [])
        # é™åˆ¶è®°å¿†è½®æ•°
        if len(mem) > MAX_TURNS * 2:
            SESSION_MEMORIES[session_id] = mem[-MAX_TURNS * 2:]
        return SESSION_MEMORIES[session_id]

    def ask(self, query: str, session_id: str = "default") -> str:
        try:
            # 1) è¯­ä¹‰æ£€ç´¢
            docs = self.retriever.get_relevant_documents(query)
            context = "\n\n".join([d.page_content for d in docs]) if docs else "ï¼ˆçŸ¥è¯†åº“æš‚æ— ç›¸å…³å†…å®¹ï¼‰"

            # 2) ç»„è£… Promptï¼ˆå«çŸ¥è¯†+äººè®¾+å†å²å¯¹è¯ï¼‰
            system_msg = (
                f"{self.role}\n"
                f"ä½ å¿…é¡»åŸºäºã€å·²çŸ¥èµ„æ–™ã€‘ä¼˜å…ˆä½œç­”ï¼Œæ— æ³•ç¡®è®¤æ—¶è¯·æ˜ç¡®è¯´æ˜ã€‚\n"
                f"ã€å·²çŸ¥èµ„æ–™ã€‘:\n{context}"
            )

            messages = [{"role": "system", "content": system_msg}]
            # åŠ å…¥ä¼šè¯è®°å¿†
            history = self._get_memory(session_id)
            messages.extend(history)
            # å½“å‰ç”¨æˆ·æ¶ˆæ¯
            messages.append({"role": "user", "content": query})

            # 3) è°ƒç”¨ DeepSeek
            resp = self.client.chat.completions.create(
                model="deepseek-chat",
                messages=messages
            )
            answer = resp.choices[0].message.content

            # 4) æ›´æ–°è®°å¿†
            history.append({"role": "user", "content": query})
            history.append({"role": "assistant", "content": answer})

            return answer

        except Exception as e:
            print("âŒ ç”Ÿæˆå›ç­”å‡ºé”™ï¼š", e)
            return "æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚è¯·ç¨åå†è¯•ã€‚"


# å¯¹å¤–æ–¹æ³•
def create_bot() -> DeepSeekBot:
    bot = DeepSeekBot()
    print("âœ… DeepSeek æœºå™¨äººåˆå§‹åŒ–å®Œæˆã€‚")
    return bot
